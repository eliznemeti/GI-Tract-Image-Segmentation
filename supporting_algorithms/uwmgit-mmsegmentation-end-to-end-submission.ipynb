{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Requirement '../input/mmdetection/addict-2.4.0-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/elizabethnemeti/Documents/GitHub/GI-Segmentation-SU24/input/mmdetection/addict-2.4.0-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Requirement '../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/elizabethnemeti/Documents/GitHub/GI-Segmentation-SU24/input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Requirement '../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/Users/elizabethnemeti/Documents/GitHub/GI-Segmentation-SU24/input/mmdetection/terminaltables-3.1.0-py3-none-any.whl'\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mzsh:1: no matches found: ../input/mmdetection/einops*\n",
      "\u001b[33mWARNING: Requirement '../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl' looks like a filename, but the file does not exist\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "sys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1\")\n",
    "sys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\n",
    "sys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\n",
    "\n",
    "!pip install ../input/mmdetection/addict-2.4.0-py3-none-any.whl > /dev/null\n",
    "!pip install ../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n",
    "!pip install ../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n",
    "!pip install ../input/mmdetection/einops* > /dev/null\n",
    "!pip install ../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Install mmsegmentation \n",
    "\n",
    "This is from my own [mmseg github repo](https://github.com/CarnoZhao/Kaggle-UWMGIT) (leave a star if you like it!)\n",
    "\n",
    "I have integrated `segmentation_models_pytorch` in this version of `mmsegmentation`. Although `segmentation_models_pytorch`'s simple Unet performs better than some models of `mmsegmentation`, anyway, `mmsegmentation` is still a good library for segmentation task when you want to compare various models in a unified training pipeline.\n",
    "\n",
    "I only hard-coded `smp.Unet` in `./mmseg/models/segmentors/smp_models.py`. You can add more `smp` models in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Kaggle-UWMGIT'...\n",
      "remote: Enumerating objects: 6283, done.\u001b[K\n",
      "remote: Counting objects: 100% (6283/6283), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1335/1335), done.\u001b[K\n",
      "remote: Total 6283 (delta 4926), reused 6238 (delta 4890), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (6283/6283), 10.77 MiB | 10.18 MiB/s, done.\n",
      "Resolving deltas: 100% (4926/4926), done.\n",
      "Obtaining file:///Users/elizabethnemeti/Documents/GitHub/GI-Segmentation-SU24/supporting_algorithms/Kaggle-UWMGIT\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /Users/elizabethnemeti/UNETENV/lib/python3.11/site-packages (from mmsegmentation==0.20.2) (3.9.0)\n",
      "Requirement already satisfied: numpy in /Users/elizabethnemeti/UNETENV/lib/python3.11/site-packages (from mmsegmentation==0.20.2) (1.24.3)\n",
      "Requirement already satisfied: packaging in /Users/elizabethnemeti/UNETENV/lib/python3.11/site-packages (from mmsegmentation==0.20.2) (24.0)\n",
      "Collecting prettytable (from mmsegmentation==0.20.2)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/CarnoZhao/Kaggle-UWMGIT && cd Kaggle-UWMGIT && pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Read csv and extract meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\n",
    "df_train = df_train.sort_values([\"id\", \"class\"]).reset_index(drop = True)\n",
    "df_train[\"patient\"] = df_train.id.apply(lambda x: x.split(\"_\")[0])\n",
    "df_train[\"days\"] = df_train.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "\n",
    "all_image_files = sorted(glob.glob(\"../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png\"), key = lambda x: x.split(\"/\")[3] + \"_\" + x.split(\"/\")[5])\n",
    "size_x = [int(os.path.basename(_)[:-4].split(\"_\")[-4]) for _ in all_image_files]\n",
    "size_y = [int(os.path.basename(_)[:-4].split(\"_\")[-3]) for _ in all_image_files]\n",
    "spacing_x = [float(os.path.basename(_)[:-4].split(\"_\")[-2]) for _ in all_image_files]\n",
    "spacing_y = [float(os.path.basename(_)[:-4].split(\"_\")[-1]) for _ in all_image_files]\n",
    "df_train[\"image_files\"] = np.repeat(all_image_files, 3)\n",
    "df_train[\"spacing_x\"] = np.repeat(spacing_x, 3)\n",
    "df_train[\"spacing_y\"] = np.repeat(spacing_y, 3)\n",
    "df_train[\"size_x\"] = np.repeat(size_x, 3)\n",
    "df_train[\"size_y\"] = np.repeat(size_y, 3)\n",
    "df_train[\"slice\"] = np.repeat([int(os.path.basename(_)[:-4].split(\"_\")[-5]) for _ in all_image_files], 3)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Make mmseg-format data (2.5D by default)\n",
    "\n",
    "\n",
    "Here, I used 2.5d data with stride=2. Thanks this good trick from [https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_decode(mask_rle, shape):\n",
    "    s = np.array(mask_rle.split(), dtype=int)\n",
    "    starts, lengths = s[0::2] - 1, s[1::2]\n",
    "    ends = starts + lengths\n",
    "    h, w = shape\n",
    "    img = np.zeros((h * w,), dtype = np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo : hi] = 1\n",
    "    return img.reshape(shape)\n",
    "\n",
    "!mkdir -p ./mmseg_train/{images,labels,splits}\n",
    "for day, group in tqdm(df_train.groupby(\"days\")):\n",
    "    patient = group.patient.iloc[0]\n",
    "    imgs = []\n",
    "    msks = []\n",
    "    file_names = []\n",
    "    for file_name in group.image_files.unique():\n",
    "        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n",
    "        segms = group.loc[group.image_files == file_name]\n",
    "        masks = {}\n",
    "        for segm, label in zip(segms.segmentation, segms[\"class\"]):\n",
    "            if not pd.isna(segm):\n",
    "                mask = rle_decode(segm, img.shape[:2])\n",
    "                masks[label] = mask\n",
    "            else:\n",
    "                masks[label] = np.zeros(img.shape[:2], dtype = np.uint8)\n",
    "        masks = np.stack([masks[k] for k in sorted(masks)], -1)\n",
    "        imgs.append(img)\n",
    "        msks.append(masks)\n",
    "        \n",
    "    imgs = np.stack(imgs, 0)\n",
    "    msks = np.stack(msks, 0)\n",
    "    for i in range(msks.shape[0]):\n",
    "        img = imgs[[max(0, i - 2), i, min(imgs.shape[0] - 1, i + 2)]].transpose(1,2,0) # 2.5d data\n",
    "        msk = msks[i]\n",
    "        new_file_name = f\"{day}_{i}.png\"\n",
    "        cv2.imwrite(f\"./mmseg_train/images/{new_file_name}\", img)\n",
    "        cv2.imwrite(f\"./mmseg_train/labels/{new_file_name}\", msk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Make fold splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_files = glob.glob(\"./mmseg_train/images/*\")\n",
    "patients = [os.path.basename(_).split(\"_\")[0] for _ in all_image_files]\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "split = list(GroupKFold(5).split(patients, groups = patients))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(split):\n",
    "    with open(f\"./mmseg_train/splits/fold_{fold}.txt\", \"w\") as f:\n",
    "        for idx in train_idx:\n",
    "            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")\n",
    "    with open(f\"./mmseg_train/splits/holdout_{fold}.txt\", \"w\") as f:\n",
    "        for idx in valid_idx:\n",
    "            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "\n",
    "## 4.1 Make config\n",
    "\n",
    "This is only **a simple baseline**, you can change anything in it\n",
    "\n",
    "From my own experiment, when using larger backbone, larger image size and more augs, the public score will be easily exceed 0.865.\n",
    "\n",
    "Here, I only train for 1k iters. **More iters are required to get a valid score**.\n",
    "\n",
    "I have made a single model submission scored 0.878 using this training pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat <<EOT >> ./Kaggle-UWMGIT/config.py\n",
    "num_classes = 3\n",
    "\n",
    "# model settings\n",
    "norm_cfg = dict(type='SyncBN', requires_grad=True)\n",
    "loss = [\n",
    "    dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
    "]\n",
    "model = dict(\n",
    "    type='SMPUnet',\n",
    "    backbone=dict(\n",
    "        type='timm-efficientnet-b0',\n",
    "        pretrained=\"imagenet\"\n",
    "    ),\n",
    "    decode_head=dict(\n",
    "        num_classes=num_classes,\n",
    "        align_corners=False,\n",
    "        loss_decode=loss\n",
    "    ),\n",
    "    # model training and testing settings\n",
    "    train_cfg=dict(),\n",
    "    test_cfg=dict(mode=\"whole\", multi_label=True))\n",
    "\n",
    "# dataset settings\n",
    "dataset_type = 'CustomDataset'\n",
    "data_root = '../mmseg_train/'\n",
    "classes = ['large_bowel', 'small_bowel', 'stomach']\n",
    "palette = [[0,0,0], [128,128,128], [255,255,255]]\n",
    "img_norm_cfg = dict(mean=[0,0,0], std=[1,1,1], to_rgb=True)\n",
    "size = 256\n",
    "albu_train_transforms = [\n",
    "    dict(type='RandomBrightnessContrast', p=0.5),\n",
    "]\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n",
    "    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n",
    "    dict(type='Albu', transforms=albu_train_transforms),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(size, size),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **img_norm_cfg),\n",
    "            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "data = dict(\n",
    "    samples_per_gpu=8,\n",
    "    workers_per_gpu=4,\n",
    "    train=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        img_suffix=\".png\",\n",
    "        seg_map_suffix='.png',\n",
    "        split=\"splits/fold_0.txt\",\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=train_pipeline),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        img_dir='images',\n",
    "        ann_dir='labels',\n",
    "        img_suffix=\".png\",\n",
    "        seg_map_suffix='.png',\n",
    "        split=\"splits/holdout_0.txt\",\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=test_pipeline),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        multi_label=True,\n",
    "        data_root=data_root,\n",
    "        test_mode=True,\n",
    "        img_dir='test/images',\n",
    "        ann_dir='test/labels',\n",
    "        img_suffix=\".jpg\",\n",
    "        seg_map_suffix='.png',\n",
    "        classes=classes,\n",
    "        palette=palette,\n",
    "        pipeline=test_pipeline))\n",
    "\n",
    "# yapf:disable\n",
    "log_config = dict(\n",
    "    interval=50,\n",
    "    hooks=[\n",
    "        dict(type='CustomizedTextLoggerHook', by_epoch=False),\n",
    "    ])\n",
    "# yapf:enable\n",
    "dist_params = dict(backend='nccl')\n",
    "log_level = 'INFO'\n",
    "load_from = None\n",
    "resume_from = None\n",
    "workflow = [('train', 1)]\n",
    "cudnn_benchmark = True\n",
    "\n",
    "total_iters = 1\n",
    "# optimizer\n",
    "optimizer = dict(type='AdamW', lr=1e-3, betas=(0.9, 0.999), weight_decay=0.05)\n",
    "optimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')\n",
    "# learning policy\n",
    "lr_config = dict(policy='poly',\n",
    "                 warmup='linear',\n",
    "                 warmup_iters=500,\n",
    "                 warmup_ratio=1e-6,\n",
    "                 power=1.0, min_lr=0.0, by_epoch=False)\n",
    "# runtime settings\n",
    "find_unused_parameters=True\n",
    "runner = dict(type='IterBasedRunner', max_iters=int(total_iters * 1000))\n",
    "checkpoint_config = dict(by_epoch=False, interval=int(total_iters * 1000), save_optimizer=False)\n",
    "evaluation = dict(by_epoch=False, interval=min(5000, int(total_iters * 1000)), metric=['imDice', 'mDice'], pre_eval=True)\n",
    "fp16 = dict()\n",
    "\n",
    "work_dir = f'./work_dirs/tract/baseline'\n",
    "EOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Let's start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstall for inner bash usage\n",
    "!cp -r ../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1 ./ && cd segmentation_models.pytorch-0.2.1  && pip install -e .\n",
    "!cp -r ../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd Kaggle-UWMGIT\n",
    "\n",
    "python ./tools/train.py ./config.py --gpu-ids 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inferencing\n",
    "\n",
    "## 5.1 Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./Kaggle-UWMGIT')\n",
    "from mmseg.apis import init_segmentor, inference_segmentor\n",
    "from mmcv.utils import config\n",
    "\n",
    "cfgs = [\n",
    "    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/config.py\",\n",
    "]\n",
    "\n",
    "ckpts = [\n",
    "    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\",\n",
    "]\n",
    "\n",
    "models = []\n",
    "for cfg, ckpt in zip(cfgs, ckpts):\n",
    "    cfg = config.Config.fromfile(cfg)\n",
    "    cfg.model.backbone.pretrained = None\n",
    "    cfg.model.test_cfg.logits = True\n",
    "    cfg.data.test.pipeline[1].transforms.insert(2, dict(type=\"Normalize\", mean=[0,0,0], std=[1,1,1], to_rgb=False))\n",
    "\n",
    "    model = init_segmentor(cfg, ckpt)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Make test submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.ndimage import binary_closing, binary_opening, measurements\n",
    "\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "classes = ['large_bowel', 'small_bowel', 'stomach']\n",
    "data_dir = \"../input/uw-madison-gi-tract-image-segmentation/\"\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "sub = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\n",
    "test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n",
    "\n",
    "if len(test_images) == 0:\n",
    "    test_dir = os.path.join(data_dir, \"train\")\n",
    "    sub = pd.read_csv(os.path.join(data_dir, \"train.csv\"))[[\"id\", \"class\"]].iloc[:100 * 3]\n",
    "    sub[\"predicted\"] = \"\"\n",
    "    test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n",
    "    \n",
    "id2img = {_.rsplit(\"/\", 4)[2] + \"_\" + \"_\".join(_.rsplit(\"/\", 4)[4].split(\"_\")[:2]): _ for _ in test_images}\n",
    "sub[\"file_name\"] = sub.id.map(id2img)\n",
    "sub[\"days\"] = sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n",
    "fname2index = {f + c: i for f, c, i in zip(sub.file_name, sub[\"class\"], sub.index)}\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Start Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = []\n",
    "for day, group in tqdm(sub.groupby(\"days\")):\n",
    "    imgs = []\n",
    "    for file_name in group.file_name.unique():\n",
    "        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n",
    "        old_size = img.shape[:2]\n",
    "        s = int(os.path.basename(file_name).split(\"_\")[1])\n",
    "        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n",
    "        file_names = [_ for _ in file_names if os.path.exists(_)]\n",
    "        imgs = [cv2.imread(file_names[0], cv2.IMREAD_ANYDEPTH)] + [img] + [cv2.imread(file_names[-1], cv2.IMREAD_ANYDEPTH)]\n",
    "        \n",
    "        new_img = np.stack(imgs, -1)\n",
    "        new_img = new_img.astype(np.float32) / new_img.max()\n",
    "\n",
    "        res = [inference_segmentor(model, new_img)[0] for model in models]\n",
    "        res = (sum(res) / len(res)).round().astype(np.uint8)\n",
    "        res = cv2.resize(res, old_size[::-1], interpolation = cv2.INTER_NEAREST)\n",
    "        for j in range(3):\n",
    "            rle = rle_encode(res[...,j])\n",
    "            index = fname2index[file_name + classes[j]]\n",
    "            sub.loc[index, \"predicted\"] = rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Format submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub[[\"id\", \"class\", \"predicted\"]]\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 3495119,
     "sourceId": 27923,
     "sourceType": "competition"
    },
    {
     "datasetId": 255887,
     "sourceId": 699609,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2102274,
     "sourceId": 3492503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1661473,
     "sourceId": 3538176,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2144343,
     "sourceId": 3568891,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 1027206,
     "sourceId": 3951115,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30185,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (UNETENV)",
   "language": "python",
   "name": "unetenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
