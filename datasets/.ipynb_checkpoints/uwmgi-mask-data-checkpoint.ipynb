{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":27923,"databundleVersionId":3495119,"sourceType":"competition"}],"dockerImageVersionId":30178,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [UW-Madison GI Tract Image Segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)\n> Track healthy organs in medical scans to improve cancer treatment\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/27923/logos/header.png?t=2021-06-02-20-30-25\">","metadata":{}},{"cell_type":"markdown","source":"# Methodology\n* In this notebook, I'll demonstrate how to create dataset from **run_length_encode** mask. \n* As it takes quite some to convert **rle** masks to **seantic** masks on-fly, we'll pre-computed the **semantic** masks and save them to avoid **bottleneck** during training.\n* I\"ll also be using **Weights & Biases** for interactive visualization.","metadata":{}},{"cell_type":"markdown","source":"# Notebooks\nðŸ“Œ **2.5D-TransUnet**:\n* Train: [UWMGI: TransUNet 2.5D [Train] [TF]](https://www.kaggle.com/code/awsaf49/uwmgi-transunet-2-5d-train-tf)\n\nðŸ“Œ **2.5D**:\n* Train: [UWMGI: 2.5D [Train] [PyTorch]](https://www.kaggle.com/awsaf49/uwmgi-2-5d-train-pytorch/)\n* Infer: [UWMGI: 2.5D [Infer] [PyTorch]](https://www.kaggle.com/awsaf49/uwmgi-2-5d-infer-pytorch/)\n* Data: [UWMGI: 2.5D stride=2 Data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data/)\n* Dataset: [UWMGI: 2.5D stride=2 Dataset](https://www.kaggle.com/datasets/awsaf49/uwmgi-25d-stride2-dataset)\n\nðŸ“Œ **UNet**:\n* Train: [UWMGI: Unet [Train] [PyTorch]](https://www.kaggle.com/code/awsaf49/uwmgi-unet-train-pytorch/)\n* Infer: [UWMGI: Unet [Infer] [PyTorch]](https://www.kaggle.com/code/awsaf49/uwmgi-unet-infer-pytorch/)\n\nðŸ“Œ **MMDetection**:\n* Train: [UWMGI: MMDetection [Train]](https://www.kaggle.com/code/awsaf49/uwmgi-mmdetection-train)\n\nðŸ“Œ **Data/Dataset**:\n* Data: [UWMGI: Mask Data](https://www.kaggle.com/datasets/awsaf49/uwmgi-mask-data)\n* Dataset: [UWMGI: Mask Dataset](https://www.kaggle.com/datasets/awsaf49/uwmgi-mask-dataset)","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install wandb --upgrade","metadata":{"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.options.plotting.backend = \"plotly\"\nimport random\nfrom glob import glob\nimport os, shutil\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport time\nimport copy\nimport joblib\nimport gc\nfrom IPython import display as ipd\nfrom joblib import Parallel, delayed\n\n# visualization\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\nimport tensorflow as tf","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T18:57:56.536759Z","iopub.execute_input":"2022-06-07T18:57:56.537235Z","iopub.status.idle":"2022-06-07T18:58:02.555981Z","shell.execute_reply.started":"2022-06-07T18:57:56.537201Z","shell.execute_reply":"2022-06-07T18:58:02.554815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# WandB\n\n<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\" width=\"400\" alt=\"Weights & Biases\" />\n\nWeights & Biases (W&B) is MLOps platform for tracking our experiemnts. We can use it to Build better models faster with experiment tracking, dataset versioning, and model management. Some of the cool features of **W&B**:\n\n* Track, compare, and visualize ML experiments\n* Get live metrics, terminal logs, and system stats streamed to the centralized dashboard.\n* Explain how your model works, show graphs of how model versions improved, discuss bugs, and demonstrate progress towards milestones.\n\nHow to find `WANDB_API_KEY`?\n1. Login to [wandb.ai](https://wandb.ai/login).\n2. Goto your [Settings](https://app.wandb.ai/settings) Page.\n3. Scroll down and select `NEW_KEY`  in `API keys` tab.","metadata":{}},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    api_key = user_secrets.get_secret(\"WANDB\")\n    wandb.login(key=api_key)\nexcept:\n    wandb.login(anonymous='must',relogin=True)\n    print('To use your W&B account,\\nGo to Add-ons -> Secrets and provide your W&B access token. Use the Label name as WANDB. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:02.558317Z","iopub.execute_input":"2022-06-07T18:58:02.558714Z","iopub.status.idle":"2022-06-07T18:58:03.414321Z","shell.execute_reply.started":"2022-06-07T18:58:02.558676Z","shell.execute_reply":"2022-06-07T18:58:03.413282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configs","metadata":{}},{"cell_type":"code","source":"NUM_LOG = 1000 # for WandB interactive Visualiztion\nNO_EMPTY = True # set False to include images with empty mask in WandB","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:03.415845Z","iopub.execute_input":"2022-06-07T18:58:03.416105Z","iopub.status.idle":"2022-06-07T18:58:03.421702Z","shell.execute_reply.started":"2022-06-07T18:58:03.416073Z","shell.execute_reply":"2022-06-07T18:58:03.420456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"markdown","source":"## RLE","metadata":{}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = np.asarray(mask_rle.split(), dtype=int)\n    starts = s[0::2] - 1\n    lengths = s[1::2]\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:03.424339Z","iopub.execute_input":"2022-06-07T18:58:03.425423Z","iopub.status.idle":"2022-06-07T18:58:03.436108Z","shell.execute_reply.started":"2022-06-07T18:58:03.425279Z","shell.execute_reply":"2022-06-07T18:58:03.435338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metadata","metadata":{}},{"cell_type":"code","source":"def get_metadata(row):\n    data = row['id'].split('_')\n    case = int(data[0].replace('case',''))\n    day = int(data[1].replace('day',''))\n    slice_ = int(data[-1])\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row\n\ndef path2info(row):\n    path = row['image_path']\n    data = path.split('/')\n    slice_ = int(data[-1].split('_')[1])\n    case = int(data[-3].split('_')[0].replace('case',''))\n    day = int(data[-3].split('_')[1].replace('day',''))\n    width = int(data[-1].split('_')[2])\n    height = int(data[-1].split('_')[3])\n    row['height'] = height\n    row['width'] = width\n    row['case'] = case\n    row['day'] = day\n    row['slice'] = slice_\n    return row","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:03.437225Z","iopub.execute_input":"2022-06-07T18:58:03.437993Z","iopub.status.idle":"2022-06-07T18:58:03.456337Z","shell.execute_reply.started":"2022-06-07T18:58:03.43796Z","shell.execute_reply":"2022-06-07T18:58:03.455211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mask","metadata":{}},{"cell_type":"code","source":"def id2mask(id_, df=None):\n    idf = df[df['id']==id_]\n    wh = idf[['height','width']].iloc[0]\n    shape = (wh.height, wh.width, 3)\n    mask = np.zeros(shape, dtype=np.uint8)\n    for i, class_ in enumerate(['large_bowel', 'small_bowel', 'stomach']):\n        cdf = idf[idf['class']==class_]\n        rle = cdf.segmentation.squeeze()\n        if len(cdf) and not pd.isna(rle):\n            mask[..., i] = rle_decode(rle, shape[:2])\n    return mask\n\ndef rgb2gray(mask):\n    pad_mask = np.pad(mask, pad_width=[(0,0),(0,0),(1,0)])\n    gray_mask = pad_mask.argmax(-1)\n    return gray_mask\n\ndef gray2rgb(mask):\n    rgb_mask = tf.keras.utils.to_categorical(mask, num_classes=4)\n    return rgb_mask[..., 1:].astype(mask.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:03.457717Z","iopub.execute_input":"2022-06-07T18:58:03.457967Z","iopub.status.idle":"2022-06-07T18:58:03.471213Z","shell.execute_reply.started":"2022-06-07T18:58:03.457937Z","shell.execute_reply":"2022-06-07T18:58:03.47035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image","metadata":{}},{"cell_type":"code","source":"def load_img(path):\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    img = img.astype('float32') # original is uint16\n    img = (img - img.min())/(img.max() - img.min())*255.0 # scale image to [0, 255]\n    img = img.astype('uint8')\n    return img\n\ndef show_img(img, mask=None):\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n    img = clahe.apply(img)\n#     plt.figure(figsize=(10,10))\n    plt.imshow(img, cmap='bone')\n    \n    if mask is not None:\n        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n        plt.imshow(mask, alpha=0.5)\n        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n        labels = [ \"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n        plt.legend(handles,labels)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:03.945252Z","iopub.execute_input":"2022-06-07T18:58:03.945571Z","iopub.status.idle":"2022-06-07T18:58:03.956558Z","shell.execute_reply.started":"2022-06-07T18:58:03.945536Z","shell.execute_reply":"2022-06-07T18:58:03.955565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Meta Data","metadata":{}},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\ndf = df.progress_apply(get_metadata, axis=1)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T18:58:05.263917Z","iopub.execute_input":"2022-06-07T18:58:05.26423Z","iopub.status.idle":"2022-06-07T19:01:26.098241Z","shell.execute_reply.started":"2022-06-07T18:58:05.264199Z","shell.execute_reply":"2022-06-07T19:01:26.096953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"paths = glob('/kaggle/input/uw-madison-gi-tract-image-segmentation/train/*/*/*/*')\npath_df = pd.DataFrame(paths, columns=['image_path'])\npath_df = path_df.progress_apply(path2info, axis=1)\ndf = df.merge(path_df, on=['case','day','slice'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:01:50.780416Z","iopub.execute_input":"2022-06-07T19:01:50.782762Z","iopub.status.idle":"2022-06-07T19:03:44.302648Z","shell.execute_reply.started":"2022-06-07T19:01:50.782698Z","shell.execute_reply":"2022-06-07T19:03:44.301914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Mask","metadata":{}},{"cell_type":"code","source":"row=1; col=4\nplt.figure(figsize=(5*col,5*row))\nfor i, id_ in enumerate(df[~df.segmentation.isna()].sample(frac=1.0)['id'].unique()[:row*col]):\n    img = load_img(df[df['id']==id_].image_path.iloc[0])\n    mask = id2mask(id_,df=df)*255\n    plt.subplot(row, col, i+1)\n    i+=1\n    show_img(img, mask=mask)\n    plt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:07:23.319039Z","iopub.execute_input":"2022-06-07T19:07:23.319924Z","iopub.status.idle":"2022-06-07T19:07:24.743102Z","shell.execute_reply.started":"2022-06-07T19:07:23.31987Z","shell.execute_reply":"2022-06-07T19:07:24.742429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Initiate **Wandb** Project","metadata":{}},{"cell_type":"code","source":"# Initialize WANDB project\nrun = wandb.init(project='uwmgi-mask-data', \n                 config={},\n#                  anonymous=anonymous,\n                 name=f\"mask-data-noresize-v2\",\n                )\n# Columns for wandb table\ncolumns=[\"id\", \"case\", \"day\", \"slice\", \"empty\", \"image\"]\n# Initialize table\ntable = wandb.Table(columns=columns)\n# Labels for mask\nclass_labels = {\n#     0:\"Background\",\n    1:\"Large Bowel\",\n    2:\"Small Bowel\",\n    3:\"Stomach\",\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:33:09.476864Z","iopub.execute_input":"2022-06-07T19:33:09.477206Z","iopub.status.idle":"2022-06-07T19:33:16.307911Z","shell.execute_reply.started":"2022-06-07T19:33:09.477174Z","shell.execute_reply":"2022-06-07T19:33:16.306959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Write Mask","metadata":{}},{"cell_type":"code","source":"def save_mask(id_,df=None, count=0):\n    idf = df[df['id']==id_]\n    mask = id2mask(id_, df=df) # mask from [0, 1] to [0, 255]\n    image_path = idf.image_path.iloc[0]\n    img = load_img(image_path) # load image\n    mask_path = image_path.replace('/kaggle/input/','/tmp/png/')\n    mask_folder = mask_path.rsplit('/',1)[0]\n    os.makedirs(mask_folder, exist_ok=True)\n    cv2.imwrite(mask_path, mask*255, [cv2.IMWRITE_PNG_COMPRESSION, 1]) # write mask as .png\n    mask_path2 = image_path.replace('/kaggle/input/','/tmp/np/').replace('.png','.npy')\n    mask_folder2 = mask_path2.rsplit('/',1)[0]\n    os.makedirs(mask_folder2, exist_ok=True)\n    np.save(mask_path2, mask*255) # write mask as .npy\n    # log each image in WandB table\n    if count<=NUM_LOG:\n        img = cv2.resize(img, dsize=(160, 192), interpolation=cv2.INTER_AREA)\n        mask = cv2.resize(mask, dsize=(160, 192), interpolation=cv2.INTER_NEAREST)\n        table.add_data(id_, \n                       idf.case.iloc[0], \n                       idf.day.iloc[0],\n                       idf.slice.iloc[0],\n                       int(mask.sum()==0),\n                       wandb.Image(img, masks={\n    #         \"predictions\" : {\n    #             \"mask_data\" : prediction,\n    #             \"class_labels\" : class_labels\n    #         },\n            \"ground_truth\" : {\n                \"mask_data\" : rgb2gray(mask), # (height, width, 3) => (height, width) => may lose overlap data\n                \"class_labels\" : class_labels\n            }}))\n    return mask_path","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:33:34.955046Z","iopub.execute_input":"2022-06-07T19:33:34.955391Z","iopub.status.idle":"2022-06-07T19:33:34.968652Z","shell.execute_reply.started":"2022-06-07T19:33:34.955344Z","shell.execute_reply":"2022-06-07T19:33:34.967556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = df.copy()\nif NO_EMPTY:\n    tmp_df = tmp_df[~df.segmentation.isna()]\nids = tmp_df['id'].unique()\n# Save Mask\n_ = Parallel(n_jobs=-1, backend='threading')(delayed(save_mask)(id_, df=tmp_df, count=i)\\\n                                             for i, id_ in enumerate(tqdm(ids, total=len(ids))))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-07T19:33:47.617067Z","iopub.execute_input":"2022-06-07T19:33:47.617466Z","iopub.status.idle":"2022-06-07T19:33:52.803277Z","shell.execute_reply.started":"2022-06-07T19:33:47.617427Z","shell.execute_reply":"2022-06-07T19:33:52.802399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Log & Display **WandB** Table","metadata":{}},{"cell_type":"code","source":"# Log table to WandB\nwandb.log({\"Table\":table})\n# Finish The Run\nwandb.finish()\n# Display the Run\ndisplay(ipd.IFrame(run.url, width=1000, height=720))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T19:34:04.22184Z","iopub.execute_input":"2022-06-07T19:34:04.222197Z","iopub.status.idle":"2022-06-07T19:34:14.555199Z","shell.execute_reply.started":"2022-06-07T19:34:04.22216Z","shell.execute_reply":"2022-06-07T19:34:14.554118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Access **WandB** tables","metadata":{}},{"cell_type":"code","source":"with wandb.init(project='uwmgi-mask-data') as run2:\n    table2= run2.use_artifact(f\"run-{run.id}-Table:v0\").get(\"Table\")\n    \nfor idx, row in table2.iterrows():\n    break\nplt.figure(figsize=(5,5))\nplt.imshow(np.array(row[-1].image))\n# plt.imshow(row[1]._masks[\"ground_truth\"]._val[\"mask_data\"].astype('uint8')*255)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.777858Z","iopub.status.idle":"2022-05-15T15:34:13.778378Z","shell.execute_reply.started":"2022-05-15T15:34:13.778131Z","shell.execute_reply":"2022-05-15T15:34:13.778158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check Saved Mask","metadata":{}},{"cell_type":"code","source":"i = 250\nimg = load_img(df.image_path.iloc[i])\nmask_path = df['image_path'].iloc[i].replace('/kaggle/input/','/tmp/png/')\nmask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\nplt.figure(figsize=(5,5))\nshow_img(img, mask=mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.779892Z","iopub.status.idle":"2022-05-15T15:34:13.780343Z","shell.execute_reply.started":"2022-05-15T15:34:13.780108Z","shell.execute_reply":"2022-05-15T15:34:13.780133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i = 250\nimg = load_img(df.image_path.iloc[i])\nmask_path = df['image_path'].iloc[i].replace('/kaggle/input/','/tmp/np/').replace('.png','.npy')\nmask = np.load(mask_path)\nplt.figure(figsize=(5,5))\nshow_img(img, mask=mask)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.781992Z","iopub.status.idle":"2022-05-15T15:34:13.783002Z","shell.execute_reply.started":"2022-05-15T15:34:13.782621Z","shell.execute_reply":"2022-05-15T15:34:13.782651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save Metadata","metadata":{}},{"cell_type":"code","source":"df['mask_path'] = df.image_path.str.replace('/kaggle/input','/kaggle/input/uwmgi-mask-dataset/png/')\ndf.to_csv('train.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.784623Z","iopub.status.idle":"2022-05-15T15:34:13.785082Z","shell.execute_reply.started":"2022-05-15T15:34:13.78484Z","shell.execute_reply":"2022-05-15T15:34:13.784864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compress Files","metadata":{}},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/png',\n                    'zip',\n                    '/tmp/png',\n                    'uw-madison-gi-tract-image-segmentation')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.786983Z","iopub.status.idle":"2022-05-15T15:34:13.787306Z","shell.execute_reply.started":"2022-05-15T15:34:13.787145Z","shell.execute_reply":"2022-05-15T15:34:13.787166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('/kaggle/working/np',\n                    'zip',\n                    '/tmp/np',\n                    'uw-madison-gi-tract-image-segmentation')","metadata":{"execution":{"iopub.status.busy":"2022-05-15T15:34:13.788743Z","iopub.status.idle":"2022-05-15T15:34:13.789031Z","shell.execute_reply.started":"2022-05-15T15:34:13.788883Z","shell.execute_reply":"2022-05-15T15:34:13.788898Z"},"trusted":true},"execution_count":null,"outputs":[]}]}